
# Bayesian Uncertainty Estimation using Monte Carlo Dropout in PyTorch ðŸ§ ðŸ”Ž

ðŸ§  Overview

This project demonstrates Bayesian uncertainty estimation using Monte Carlo Dropout in a neural network trained on the Breast Cancer Wisconsin Diagnostic Dataset.
Instead of returning a single prediction, the model estimates both prediction and uncertainty, which is essential for aerospace, reliability-critical ML systems, anomaly detection, and healthcare diagnostics.

Traditional deep learning returns a number.
Probabilistic deep learning returns a confidence level behind that number.

This work showcases how dropout at inference can approximate Bayesian Neural Networks, enabling models to express when they're confident or uncertain â€” a key component in trustworthy & interpretable AI.

## ðŸ“Š Dataset

Breast Cancer Wisconsin Diagnostic Dataset

Binary classification: Malignant vs Benign

30 input features per sample

Well-suited for uncertainty research & calibration studies

ðŸ“Ž Source: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

---

## ðŸš€ Project Summary

This project implements a small neural network with **dropout active at inference time**, enabling Bayesian approximation by sampling multiple forward passes.  
From these samples, we compute:

- **Mean prediction** â†’ model output
- **Standard deviation** â†’ uncertainty estimate (confidence)

This helps identify when the model is unsure â€” essential for **probabilistic deep learning and uncertainty quantification**.
| Method                 | Description                             |
| ---------------------- | --------------------------------------- |
| **Architecture**       | 2-layer MLP with Dropout                |
| **Training Objective** | Binary cross-entropy                    |
| **Bayesian Mechanism** | Dropout enabled during inference        |
| **Uncertainty Source** | Variance across multiple forward passes |


---

## ðŸ“‚ Files

| File | Description |
|------|-------------|
| `Bayesian_Uncertainty_Mini_Study.py` | Main script demonstrating Bayesian inference with dropout |

---

## ðŸ”§ Installation & Setup

```bash
# Clone repo
git clone <your_repo_link>

cd Bayesian-Uncertainty-Mini-Study

# Install required packages
pip install torch numpy
```

---

## â–¶ Run the Script

```bash
python Bayesian_Uncertainty_Mini_Study.py
```

You will see output similar to:

```
Training Completed
Prediction Mean: [0.53]
Uncertainty (Std): [0.12]
```

Higher uncertainty â†’ model is less confident.  
Lower uncertainty â†’ more reliable prediction.

---

## ðŸ“Œ Concepts Demonstrated

- Monte Carlo Dropout
- Bayesian Neural Networks (approximation)
- Uncertainty Quantification
- PyTorch experimentation workflow
- Reproducible ML mini research setup

---

## ðŸ§± Potential Extensions

Feel free to extend this project:

- Train on real datasets instead of random tensors  
- Add visualization for uncertainty distribution  
- Compare deterministic vs Bayesian behavior  
- Apply to aerospace, fault-detection, or safety-critical ML tasks  
- Add calibration metrics (ECE, reliability diagrams)  

---

## âœ¨ Author

**Shivani Sharma**  
AI/ML Engineer | Research & Deep Learning | Bayesian/Uncertainty Learning  
GitHub: https://github.com/SharmaShivani12  


